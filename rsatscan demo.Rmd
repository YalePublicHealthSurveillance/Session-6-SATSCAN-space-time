---
title: "rsatscan intro"
author: "Dan Weinberger"
date: "March 1, 2023"
output: html_document
---




```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#library(githubinstall)
#githubinstall('https://github.com/cran/rsatscan')
library(rsatscan)
library(rgdal)
library(lubridate)
library(readxl)
library(zipcodeR)
```


## Download the ZIP-code level file from NYC
Save as an .xlsx file to avoid formatting issues with their text files.
```{r}

d1 <- read_excel('./Data/nyc_spring_2020_1.xlsx')

d1$Date <- as.Date(d1$Date)
```

Restrict to 65+ year olds, between mid Feb and mid-March
```{r}
d1 <- 
  d1[d1$Dim1Name=='Zip' & d1$Dim2Value=="Ages 65+ years" &d1$Date>='2020-02-15' & d1$Date<='2020-03-20',]

cases <- d1[,c('Date','Zip','Count')]
```

Geocode the ZIPs using the geocode_zip() function and merge the coordinates back in with the ZIPs

```{r}
data(zip_code_db, package='zipcodeR')

coord1 <- geocode_zip(unique(cases$Zip))

cases2 <- merge(cases, zip_code_db[,c('zipcode','lat','lng','population')], 
                by.x='Zip', by='zipcode')
```

Export the case file
```{r}
write.csv(cases2, './Data/nyc_resp_spring2020.csv')
```


```{r}

```


## Data for rsatscan

case file just needs to have ZIP, date (Y/m/d)
```{r}
nyc_cas <- cases2[,c("Zip",'Count','Date')]
nyc_cas$Date <- paste(year(cases2$Date), month(nyc_cas$Date),day(nyc_cas$Date), sep='/')
```

geo file needs  to have one row per zip, with lat and lng
```{r}
nyc_geo <- unique(cases2[c('Zip', 'lat','lng')])
```


Read in shape file for mapping
"dsn"" gives the folder where the .shp file is saved; layer gives the name of the .shp file. Note the folder must contain the .shp files as well as the .prj, .shx, .dbf files.
```{r}
shape.NYC <- readOGR(dsn = "./Data/NYC shape files", layer = "geo_export_ef7f38de-fdc9-46c6-bf6b-36dcb40dfda8")
```

## Specify the parameters for SATSCAN and generate the input files needed
Save in a temporary directory
```{r}
invisible(ss.options(reset=TRUE)) #Reset parameters
```

Parameters for SATSCAN
```{r}
ss.options(list(CaseFile="NYC_resp.cas", PrecisionCaseTimes=3))

ss.options(c("StartDate=2020/02/15","EndDate=2020/03/20"))

ss.options(list(CoordinatesFile="NYC_resp.geo", AnalysisType=4, ModelType=2, TimeAggregationUnits=3))

ss.options(list(UseDistanceFromCenterOption="y", MaxSpatialSizeInDistanceFromCenter=3, NonCompactnessPenalty=0))

ss.options(list(MaxTemporalSizeInterpretation=1, MaxTemporalSize=7))

ss.options(list(ProspectiveStartDate="2020/03/10", ReportGiniClusters="n", LogRunToHistoryFile="n"))
```

Where to savethe output?
```{r}
td = './Manual results/'
write.ss.prm(td,  "NYC_resp")
write.cas(nyc_cas, td, "NYC_resp")
write.geo(nyc_geo, td, "NYC_resp")
```


#Run SATSCAN
Save results in an object called "NYCresp"
Need to point to directory on your computer where SATSCAN program is saved
```{r}
NYCresp = satscan(td, "NYCresp", sslocation = "C:/Program Files/SaTScan/")

#Summarize analysis
summary(NYCresp) 

#See the main results and info about each cluster
NYCresp$main

sp::plot(shape.NYC)  #Map NYC borough boundaries
sp::plot(NYCresp$shapeclust, add=T, col='red', pch=16) #Overlay the SATSCAN cluster results
```

## Or Manually read in results after running SATSCAN with these parameters

```{r}
shape.results <- readOGR(dsn = "./Manual results/NYC_resp.gis.shp")
shape.results <- readOGR(dsn = "./Manual results/NYC_resp.col.shp")
shape.results.points <- readOGR(dsn = "./Manual results/NYC_resp.gis.shp")

sp::plot(shape.NYC)  #Map NYC borough boundaries
sp::plot(shape.results, add=T, col='red', pch=16) #Overlay the SATSCAN cluster results
sp::plot(shape.results.points, add=T, col='red', pch=16) #Overlay the SATSCAN cluster results

```

Monte Carlo results
Test statistic for 999 simulations.

```{r}
mc.results <- read.table('./Manual Results/NYC_resp.llr.txt')

hist(mc.results$V1, main="Monte Carlo")
abline(v=shape.results$TEST_STAT[1], col='red')

#Calculate the P-value!
1 - sum(shape.results$TEST_STAT[1] > mc.results$V1) / length(mc.results$V1)


```


